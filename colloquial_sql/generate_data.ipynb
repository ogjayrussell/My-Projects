{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Synthetic Data \n",
    "Using OpenAI's API GPT-4 \n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import random\n",
    "import os\n",
    "import dotenv\n",
    "import llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = os.environ.get('OPENAI_API_KEY')\n",
    "\n",
    "prompt = \"\"\"A model that receives an instruction from the user to show certain information from a postgres database in colloquial english. \n",
    "Followed by information on table definitions under TABLE_DEFINITIONS formatted as the output of this function:\n",
    "\n",
    "    def get_table_definitions_for_prompt(self):\n",
    "        table_names = self.get_all_table_names()\n",
    "        return \"\\n\".join([self.get_table_definition(table) for table in table_names])\n",
    "\n",
    "With the instruction and the table definitions formatted like so:\n",
    "\n",
    "<user instruction>\n",
    "\n",
    "TABLE_DEFINITIONS\n",
    "\n",
    "<output of function>\n",
    "\n",
    "It is the model's job to then respond with an SQL query that will be run to fetch the requested data\"\"\" \n",
    "temperature = 0.4\n",
    "number_of_examples = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_example(prompt, prev_examples, temperature=.5):\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": f\"\"\"You are generating data which will be used to train a machine learning model.\\n\\n\n",
    "            You will be given a high-level description of the model we want to train, and from that, you will generate data samples, each with a prompt/response pair.\\n\\n\n",
    "            You will do so in this format:\\n```\\nprompt\\n-----------\\n$prompt_goes_here\\n-----------\\n\\nresponse\\n-----------\\n$response_goes_here\\n-----------\\n```\\n\\nOnly one prompt/response pair should be generated per turn.\\n\\nFor each turn, make the example slightly more complex than the last, while ensuring diversity.\\n\\nMake sure your samples are unique and diverse, yet high-quality and complex enough to train a well-performing model.\\n\\nHere is the type of model we want to train:\\n`{prompt}`\"\"\"\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    if len(prev_examples) > 0:\n",
    "        if len(prev_examples) > 10:\n",
    "            prev_examples = random.sample(prev_examples, 10)\n",
    "        for example in prev_examples:\n",
    "            messages.append({\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": example\n",
    "            })\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "        max_tokens=1354,\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating example 0\n",
      "['prompt\\n-----------\\nShow me the names of all employees.\\n\\nTABLE_DEFINITIONS\\n\\nemployees: id (integer), name (text), position (text), salary (integer), department_id (integer)\\n\\ndepartments: id (integer), name (text), location (text)\\n-----------\\n\\nresponse\\n-----------\\nSELECT name FROM employees;\\n-----------']\n"
     ]
    }
   ],
   "source": [
    "prev_examples = []\n",
    "for i in range(number_of_examples):\n",
    "    print(f'Generating example {i}')\n",
    "    example = generate_example(prompt, prev_examples, temperature)\n",
    "    prev_examples.append(example)\n",
    "\n",
    "print(prev_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 successfully-generated examples. Here are the first few:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Show me the names of all employees.\\n\\nTABLE_DEFINITIONS\\n\\nemployees: id (integer), name (text), position (text), salary (integer), department_id (integer)\\n\\ndepartments: id (integer), name (text), location (text)</td>\n",
       "      <td>SELECT name FROM employees;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                    prompt  \\\n",
       "0  Show me the names of all employees.\\n\\nTABLE_DEFINITIONS\\n\\nemployees: id (integer), name (text), position (text), salary (integer), department_id (integer)\\n\\ndepartments: id (integer), name (text), location (text)   \n",
       "\n",
       "                      response  \n",
       "0  SELECT name FROM employees;  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Initialize lists to store prompts and responses\n",
    "prompts = []\n",
    "responses = []\n",
    "\n",
    "# Parse out prompts and responses from examples\n",
    "for example in prev_examples:\n",
    "  try:\n",
    "    split_example = example.split('-----------')\n",
    "    prompts.append(split_example[1].strip())\n",
    "    responses.append(split_example[3].strip())\n",
    "  except:\n",
    "    pass\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'prompt': prompts,\n",
    "    'response': responses\n",
    "})\n",
    "\n",
    "# Remove duplicates\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "print('There are ' + str(len(df)) + ' successfully-generated examples. Here are the first few:')\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets, with 90% in the train set\n",
    "train_df = df.sample(frac=0.9, random_state=42)\n",
    "test_df = df.drop(train_df.index)\n",
    "\n",
    "# Save the dataframes to .jsonl files\n",
    "train_df.to_csv('train.csv', index = False)\n",
    "test_df.to_csv('test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autogen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
