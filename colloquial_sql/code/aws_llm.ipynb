{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c04e7206-3653-4358-b7e3-601fca8aa69b",
   "metadata": {},
   "source": [
    "# Training and Deploying Mistral 7B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0e9a59",
   "metadata": {},
   "source": [
    "This notebook was copied from AWS SageMaker to give insight on the workflow on model configuration and deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54e298ae-9078-42a5-8122-50d219241aad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bitsandbytes\n",
      "  Using cached bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (2.0.0.post200)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (1.26.4)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.13.3)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (4.5.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\n",
      "Using cached bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl (119.8 MB)\n",
      "Installing collected packages: bitsandbytes\n",
      "Successfully installed bitsandbytes-0.43.1\n"
     ]
    }
   ],
   "source": [
    "!pip install bitsandbytes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2fcb0d4-c24e-4b0b-bdf0-026c51304b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting peft\n",
      "  Using cached peft-0.10.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft) (23.2)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.0.0.post200)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft) (4.31.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft) (4.66.2)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.21.0)\n",
      "Requirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.4.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.22.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (3.13.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2023.6.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (4.5.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.13.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
      "Using cached peft-0.10.0-py3-none-any.whl (199 kB)\n",
      "Installing collected packages: peft\n",
      "Successfully installed peft-0.10.0\n"
     ]
    }
   ],
   "source": [
    "!pip install peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f353a0d-076e-4360-8ba3-a697b954e749",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sagemaker'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msagemaker\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mboto3\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mio\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sagemaker'"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "import io\n",
    "from sagemaker.huggingface import get_huggingface_llm_image_uri\n",
    "import json\n",
    "from sagemaker.huggingface import HuggingFaceModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18e22c6-9359-4bec-8b21-e75ad7e201d7",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "638c7f17-96e1-4131-b7ff-0fad2b67c513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker role arn: arn:aws:iam::566086704797:role/service-role/AmazonSageMaker-ExecutionRole-20240222T123141\n",
      "sagemaker session region: us-west-2\n"
     ]
    }
   ],
   "source": [
    "sess = sagemaker.Session()\n",
    "\n",
    "#preparing the necessary AWS resources and permissions to ensure \n",
    "#SageMaker can access the data it needs and has the permissions to perform operations on behalf of the user.\n",
    "\n",
    "# sagemaker_session_bucket -> used for uploading data, models and logs\n",
    "# sagemaker_will_automatically create this bucket if it not exists\n",
    "\n",
    "sagemaker_session_bucket=None\n",
    "\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e78887-d965-4789-b733-c367a4f3bb49",
   "metadata": {},
   "source": [
    "## Hugging Face Deep Learning Container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3788ede-9d4d-473c-8f2e-489432416a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm image uri: 763104351884.dkr.ecr.us-west-2.amazonaws.com/huggingface-pytorch-tgi-inference:2.0.1-tgi1.1.0-gpu-py39-cu118-ubuntu20.04\n"
     ]
    }
   ],
   "source": [
    "# retrieve the llm image uri\n",
    "llm_image = get_huggingface_llm_image_uri(\n",
    "    \"huggingface\",\n",
    "    version=\"1.1.0\"\n",
    ")\n",
    "\n",
    "# print ecr image uri\n",
    "print(f\"llm image uri: {llm_image}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34182998-bb69-48a6-adaf-7039d82a40af",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "Mistral7b sharded requires less VRAM to load the model. Quantisation requires less memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "39b0c82b-a99b-43b8-90fa-e4bc757c589f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# sagemaker config\n",
    "instance_type = \"ml.g5.xlarge\"\n",
    "n_gpu = 1\n",
    "health_check_timeout = 800\n",
    "\n",
    "# Model configuration for text generation ingerence with huggingface\n",
    "config = {\n",
    "    'HF_MODEL_ID': \"filipealmeida/Mistral-7B-Instruct-v0.1-sharded\", # model_id for Mistral 7B. \n",
    "    'SM_NUM_GPUS': json.dumps(n_gpu),\n",
    "    'MAX_INPUT_LENGTH': json.dumps(2048),  # Max length of input text\n",
    "    'MAX_TOTAL_TOKENS': json.dumps(4096),  # Max length of the generation (including input text)\n",
    "    'MAX_BATCH_TOTAL_TOKENS': json.dumps(8192),  # Limits the number of tokens that can be processed in parallel during the generation\n",
    "    'HUGGING_FACE_HUB_TOKEN': json.dumps(\"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\"),\n",
    "    'HF_MODEL_QUANTIZE': \"bitsandbytes\",  # Enable bitsandbytes quantization\n",
    "    'QUANTIZATION_BITS': json.dumps(8)  # Set quantization to 8-bit\n",
    "}\n",
    "\n",
    "# HF Model Class\n",
    "hf_model = HuggingFaceModel(\n",
    "  role=role,\n",
    "  image_uri=llm_image,\n",
    "  env=config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843ce902-5347-4918-bdb9-25a4244c2ecc",
   "metadata": {},
   "source": [
    "## Deploy Mistral 7B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c091542c-94df-45d0-bdf6-d3c51c483cc3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------!"
     ]
    }
   ],
   "source": [
    "# deploy the HuggingFaceModel to Amazon SageMaker\n",
    "# Creates an endpoint that will contain the model\n",
    "llm = hf_model.deploy(\n",
    "  initial_instance_count= 1,\n",
    "  instance_type= instance_type,\n",
    "  container_startup_health_check_timeout= health_check_timeout,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdaad3e-ebe2-43bd-b082-d391aaa2593b",
   "metadata": {},
   "source": [
    "## Structure and configure response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ef23c79-2dfc-4e71-bac8-b55a6f25af06",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = 'what are the ingredients of a meat pie'\n",
    "prompt= f'''[INST] {message} [/INST]'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c752230-fd25-4ead-9f8c-d946db7fb3e6",
   "metadata": {},
   "source": [
    "### Hyper params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e00e419-f764-4671-b927-a3a1980a943b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#config response\n",
    "input_data = {\n",
    "    'inputs':prompt,\n",
    "    'parameters':{\n",
    "        'do_sample': True,\n",
    "        'top_p': 0.6,\n",
    "        'temperature': 0.3, #low temperature because I want consistency in the answers\n",
    "        'top_k': 50,\n",
    "        'max_new_tokens': 512,\n",
    "        'repetition_penalty': 1.03\n",
    "    }\n",
    "}\n",
    "\n",
    "body_input_data_json = json.dumps(input_data)# needs to be in json format to be passed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1367aefc-b00d-4197-9298-f3da4705e79e",
   "metadata": {},
   "source": [
    "### Request the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7de56640-7862-45bf-b720-3f2fcfc9be86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sagemaker runtime client\n",
    "sagemaker_runtime = boto3.client('sagemaker-runtime')\n",
    "endpoint = 'huggingface-pytorch-tgi-inference-2024-04-26-05-43-18-580'\n",
    "content_type = 'application/json'\n",
    "\n",
    "\n",
    "# Requests inference from AWS SageMaker endpoint\n",
    "# Model deployed - Mistral 7B\n",
    "response = sagemaker_runtime.invoke_endpoint(\n",
    "    EndpointName = endpoint,\n",
    "    ContentType = content_type,\n",
    "    Body = body_input_data_json.encode('utf-8')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d70ade-6700-4b77-b1bb-c9d7b8571e9f",
   "metadata": {},
   "source": [
    "### Parse the response\n",
    "the response is given in json format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be25ab40-3d07-48d6-9cfd-88175332a82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_body = response['Body'].read().decode('utf-8')\n",
    "response_json = json.loads(response_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05a96ee6-786c-4c03-994e-31bd9beb5eac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': '[INST] what are the ingredients of a meat pie [/INST] The ingredients for a meat pie can vary depending on the recipe, but some common ingredients include:\\n\\n* Flaky pie crust\\n* Ground beef, pork, or a combination of the two\\n* Onion\\n* Garlic\\n* Carrots\\n* Peas\\n* Thyme\\n* Rosemary\\n* Salt\\n* Pepper\\n* Egg wash (optional)\\n\\nSome recipes may also include other ingredients such as mushrooms, celery, or diced tomatoes.'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1470912c-77a4-4dde-9ccf-aac438fb7da2",
   "metadata": {},
   "source": [
    "### Extract and Print Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7dbcdb03-ce7b-45c2-b933-055bec0ffdca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The ingredients for a meat pie can vary depending on the recipe, but some common ingredients include:\n",
      "\n",
      "* Flaky pie crust\n",
      "* Ground beef, pork, or a combination of the two\n",
      "* Onion\n",
      "* Garlic\n",
      "* Carrots\n",
      "* Peas\n",
      "* Thyme\n",
      "* Rosemary\n",
      "* Salt\n",
      "* Pepper\n",
      "* Egg wash (optional)\n",
      "\n",
      "Some recipes may also include other ingredients such as mushrooms, celery, or diced tomatoes.\n"
     ]
    }
   ],
   "source": [
    "generated_text = response_json[0]['generated_text']\n",
    "print(generated_text[len(prompt):])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
